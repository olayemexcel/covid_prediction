{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81381930",
   "metadata": {},
   "source": [
    "## COVID TEST FINDINGS CLASSIFICATION USING ML MODELS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ae2dc",
   "metadata": {},
   "source": [
    "sex: 1 for female and 2 for male.\n",
    "\n",
    "age: of the patient.\n",
    "\n",
    "classification: covid test findings. Values 1-3 mean that the patient was diagnosed with covid in different\n",
    "\n",
    "degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive.\n",
    "\n",
    "patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "\n",
    "pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "\n",
    "pregnancy: whether the patient is pregnant or not.\n",
    "\n",
    "diabetes: whether the patient has diabetes or not.\n",
    "\n",
    "copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "\n",
    "asthma: whether the patient has asthma or not.\n",
    "\n",
    "inmsupr: whether the patient is immunosuppressed or not.\n",
    "\n",
    "hypertension: whether the patient has hypertension or not.\n",
    "\n",
    "cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "\n",
    "renal chronic: whether the patient has chronic renal disease or not.\n",
    "\n",
    "other disease: whether the patient has other disease or not.\n",
    "\n",
    "obesity: whether the patient is obese or not.\n",
    "\n",
    "tobacco: whether the patient is a tobacco user.\n",
    "\n",
    "usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "\n",
    "medical unit: type of institution of the National Health System that provided the care.\n",
    "\n",
    "intubed: whether the patient was connected to the ventilator.\n",
    "\n",
    "icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "\n",
    "date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50818943",
   "metadata": {},
   "source": [
    "### Step 1: Load and Explore the Dataset\n",
    "#### First, we import necessary libraries and load the data for preliminary exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436eaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the Python warnings module to provides a mechanism for handling warnings that occur during program execution.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a01c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset in csv format\n",
    "df = pd.read_csv(\"Covid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a8e5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display the first 20 rows of the dataset\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677413bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display dataset table info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f838325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display dataset statistics info\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a181b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display all the dataset features or column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749e718",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing\n",
    "#### Next  required handling missing values, encode categorical variables if not encoded, and address any data inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for total null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702201f",
   "metadata": {},
   "source": [
    "##### Shows there is no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e7e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'DATE_DIED' to a binary 'DIED' feature (1 if died, 0 otherwise)\n",
    "df['DIED'] = df['DATE_DIED'].apply(lambda x: 0 if x == '9999-99-99' else 1)\n",
    "\n",
    "# Drop the original 'DATE_DIED' column\n",
    "df.drop('DATE_DIED', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the modified dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking all columns unique valus exclude 'DATE_DIED'\n",
    "features = ['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'INTUBED',\n",
    "                'PNEUMONIA', 'AGE', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',\n",
    "                'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY',\n",
    "                'RENAL_CHRONIC', 'TOBACCO', 'CLASIFFICATION_FINAL', 'ICU']\n",
    "\n",
    "\n",
    "for i in features:\n",
    "    unique_values = df[i].unique()\n",
    "    print(f\"Column: {i}, Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e4456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display all ages in sort form\n",
    "age_unique_values = df['AGE'].unique()\n",
    "age_unique_values_sorted = sorted(age_unique_values)\n",
    "\n",
    "print(f\"Unique Values in 'AGE' column (Sorted): {age_unique_values_sorted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138aa0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc4c56",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis (EDA)\n",
    "#### Visualize the data to understand the distribution and relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of ages\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['AGE'], bins=30, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d69c70",
   "metadata": {},
   "source": [
    "### Comment \n",
    "##### The histogram above  depicts the distribution of ages among COVID-19 cases within a particular dataset. It is characterized by a roughly bell-shaped curve, skewed slightly to the right, suggesting that the number of cases tends to be higher in middle-aged individuals, with a gradual decrease in frequency among older populations.\n",
    "\n",
    "##### The most common age range for COVID-19 cases in this dataset is between approximately 30 and 60 years, with the peak frequency in the 50s age group. The number of cases among the very young and elderly is significantly lower, which might reflect a variety of factors including exposure risks, social behaviors, and perhaps the data collection focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between age and COVID classification\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='CLASIFFICATION_FINAL', y='AGE', data=df)\n",
    "plt.title('COVID Classification vs Age')\n",
    "plt.xlabel('COVID Classification')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b123b7",
   "metadata": {},
   "source": [
    "### Comment\n",
    "##### This box plot visualizes the relationship between patient age and COVID-19 classification, which appears to denote the severity or status of the disease. Each box represents the interquartile range (IQR) of ages for patients within each classification, with the horizontal line inside the box marking the median age.\n",
    "\n",
    "##### Key observations from the chart are as follows:\n",
    "\n",
    "COVID Classifications 1, 2, and 3: These likely represent confirmed cases of COVID-19, with different degrees of severity. The median age for these classifications is roughly between 40 to 60 years. The age distribution for these classifications is quite similar, although classification 2 has a slightly higher median age and more variability as indicated by the longer IQR.\n",
    "\n",
    "Classifications 4, 5, 6, and 7: These might denote negative tests, inconclusive tests, or different medical classifications related to the disease. There's a noticeable shift toward a younger median age in classification 4, and the ages broaden out for classifications 5 and 6, suggesting a wider age range among those classifications. Classification 7 has a higher median age, similar to the confirmed cases, but with a very wide age range, indicating this classification affects a broad spectrum of ages.\n",
    "\n",
    "Outliers and Spread: There are outliers present, particularly in classifications 1 and 2, indicating that there are patients significantly younger than the typical age range. The spread of ages, indicated by the \"whiskers\" of the plot, is quite wide for all classifications, showing that COVID-19 affects a broad age range.\n",
    "\n",
    "For stakeholders, this chart indicates that while COVID-19 confirmed cases (classifications 1-3) tend to be more prevalent in the middle-aged groups, the disease does not exclusively affect these ages. There is significant variance and outliers, especially in classifications deemed less severe or inconclusive, pointing to the need for vigilance and healthcare support across all age groups. The relatively consistent median age across several classifications suggests that midlife adults are generally the most affected, which might inform how resources for prevention and treatment are allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0076134",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "# Check for Multi-collinearity:\n",
    "# Multi-collinearity refers to high correlations between predictor variables\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f4e30",
   "metadata": {},
   "source": [
    "### Considering the heatmap:\n",
    "\n",
    "Features such as 'INTUBED', 'PNEUMONIA', and 'ICU' have a stronger negative correlation with 'PATIENT_TYPE', which indicates their potential importance in predicting patient outcomes.\n",
    "'PREGNANT' has a high positive correlation with 'SEX', which makes sense since only females can be pregnant; thus, one of these features might be redundant but could also be critical to the health sector.\n",
    "'DIED' has a strong negative correlation with 'PATIENT_TYPE', suggesting that 'DIED' is a significant predictor of patient outcomes.\n",
    "'USMER' and 'MEDICAL_UNIT' have low correlations with other features, suggesting that they might not be as critical for the model.\n",
    "### Based on these observations:\n",
    "\n",
    "Retain 'DIED', 'INTUBED', 'PNEUMONIA', and 'ICU' due to their strong correlations with patient outcomes.\n",
    "Consider removing or combining 'PREGNANT' and 'SEX' to avoid redundancy.\n",
    "Review 'USMER' and 'MEDICAL_UNIT' for clinical significance; they could potentially be removed if they do not add predictive value or if they're not operationally relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202f881",
   "metadata": {},
   "source": [
    "### Step 4: Feature Engineering and Selection\n",
    "##### Create new features and select the most relevant features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58da7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features with correlated value of more than 0.8 but retain 'PREGNANT'\n",
    "irrelevant_columns = ['CARDIOVASCULAR', 'COPD', 'ASTHMA' , 'INMSUPR', 'OTHER_DISEASE', 'TOBACCO','USMER']\n",
    "df = df.drop(columns=irrelevant_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290db8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix after features removal\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3fa8a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize variance of numerical features\n",
    "numerical_features = df.select_dtypes(include=[np.number])\n",
    "variances = numerical_features.var()\n",
    "variances.plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for individual numeric variables\n",
    "# This helps in understanding the spread and skewness of the data.\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outlier using Boxplot\n",
    "# Plot boxplots for numeric variables\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d4feb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Statistical significance of variables:\n",
    "# For assessing the significance of categorical variables against a numerical one (e.g., 'AGE') using statistical tests like ANOVA:\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# ANOVA for a categorical variable 'SEX' against numeric variable 'AGE'\n",
    "model = ols('AGE ~ C(SEX)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84543ec",
   "metadata": {},
   "source": [
    "In summary, the above ANOVA results indicate that 'SEX' has a statistically significant effect on 'AGE' in the dataset, with a very strong degree of certainty (given the extremely low p-value). The high F-statistic further supports the conclusion that the differences in mean 'AGE' across 'SEX' are not due to random variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for class imbalance\n",
    "\n",
    "# Checking class distribution\n",
    "class_counts = df['CLASIFFICATION_FINAL'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Visualizing class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='CLASIFFICATION_FINAL', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57a19b",
   "metadata": {},
   "source": [
    "The classes are significantly imbalanced, with some classes having a substantially larger number of instances compared to others. Class imbalance can potentially lead to biased models that are more accurate at predicting the majority class but perform poorly on minority classes.\n",
    "\n",
    "Addressing class imbalance is crucial to ensure that the model is not biased toward the majority class and that all classes are adequately represented. Several techniques can be employed:\n",
    "\n",
    "Resampling Techniques: Oversampling the minority class (e.g., using techniques like SMOTE - Synthetic Minority Over-sampling Technique) or undersampling the majority class to balance the class distribution.\n",
    "\n",
    "Generating Synthetic Samples: Creating synthetic samples for the minority class to balance the dataset.\n",
    "\n",
    "Weighted Models: Assigning different weights to classes, giving higher weights to the minority class to increase their influence during model training.\n",
    "\n",
    "Different Algorithms: Using algorithms that handle class imbalance better, like ensemble methods (Random Forest, Gradient Boosting) or algorithms that inherently account for class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2c9c7",
   "metadata": {},
   "source": [
    "<b>Balancing an imbalanced dataset is crucial for models to learn effectively across all classes. A common method to address class imbalance is oversampling or undersampling. Here, I'll demonstrate oversampling using the Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f623e4",
   "metadata": {},
   "source": [
    "### SMOTE for Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55874fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('CLASIFFICATION_FINAL', axis=1)\n",
    "y = df['CLASIFFICATION_FINAL']\n",
    "\n",
    "# Initialize SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target variable into a new DataFrame\n",
    "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='CLASIFFICATION_FINAL')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution after balancing\n",
    "print(df_resampled['CLASIFFICATION_FINAL'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed952e",
   "metadata": {},
   "source": [
    "## Splitting features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a9504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting features and target\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "X = df.drop(columns=['CLASIFFICATION_FINAL'])\n",
    "y = df['CLASIFFICATION_FINAL']\n",
    "\n",
    "# Encoding categorical variables (if any)\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.copy()\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X_encoded[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "# Scaling features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "#convert y back to Dataframe\n",
    "y=y.to_frame()\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e5975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9690f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of each splitted dataset if it's okay\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24c62f",
   "metadata": {},
   "source": [
    "## Models Implementation (RFC, SVC, XGBoot, DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation and Evaluation\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bda079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Implement SVC with kernel=linear on X_train and y_train\n",
    "svm = SVC(kernel=\"linear\", probability=True)  # Enable probability estimates\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Ensure that X_test has the same columns as X_train\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Flatten y_test if it's a DataFrame\n",
    "y_test_flat = y_test.values.flatten()\n",
    "\n",
    "# Use predict_proba for obtaining class probabilities\n",
    "y_pred_svm_probs = svm.predict_proba(X_test)\n",
    "\n",
    "# Now calculate metrics\n",
    "svm_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_flat, y_pred_svm),\n",
    "    \"Precision\": precision_score(y_test_flat, y_pred_svm, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test_flat, y_pred_svm, average='weighted'),\n",
    "    \"F1-score\": f1_score(y_test_flat, y_pred_svm, average='weighted'),\n",
    "    \"AUC-ROC\": roc_auc_score(y_test_flat, y_pred_svm_probs, multi_class='ovr'),\n",
    "}\n",
    "\n",
    "print(svm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting F1 Scores for comparison\n",
    "f1_scores = {model: accuracy_score(y_test, res['predictions']) for model, res in results.items()}\n",
    "fig = go.Figure([go.Bar(x=list(f1_scores.keys()), y=list(f1_scores.values()))])\n",
    "fig.update_layout(title='Model Comparison Based on F1 Score', xaxis_title='Model', yaxis_title='F1 Score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model with the highest F1 score\n",
    "best_model_name = max(f1_scores, key=f1_scores.get)\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"The best performing model is {best_model_name} with an F1 score of {f1_scores[best_model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3046f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7c9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
